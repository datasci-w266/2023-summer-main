{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L5LQ2xlw2I9"
      },
      "source": [
        "# Lesson notebook 8 - Parsing\n",
        "\n",
        "\n",
        "\n",
        "#### NLTK Chart parser\n",
        "\n",
        "First we'll look at a chart parser from NLTK.  This parser is not pretrained.  It will operate by following the production rules in the grammar we provide.\n",
        "\n",
        "\n",
        "#### NLTK Shift Reduce parser\n",
        "\n",
        "Next we'll run the NLTK shift reduce parser.  Again, this parser is also not pre-trained so it is completely dependent on the grammar we provide.  Since we are providing a toy grammar and an ambiguous sentence we end up without a single tree as output.\n",
        "\n",
        "#### NLTK Probabilistic Chart parser\n",
        "\n",
        "Third, we'll look at a probabilistic chart parser from NLTK.  This parser is not pretrained.  It will operate by following the production rules in the grammar we provide and score the sentences.\n",
        "\n",
        "\n",
        "#### SpaCy language processing examples\n",
        "\n",
        "Finally we'll use SpaCy, a pretrained open source language processing pipeline.  It provides a platform for processing text in a number of ways without having to perform any fine-tuning.\n",
        "\n",
        "<a id = 'returnToTop'></a>\n",
        "\n",
        "## Notebook Contents\n",
        "  * 1. [NLTK Parsers](#nltk)\n",
        "    * 1.1 [NLTK Setup](#nltkSetup)\n",
        "    * 1.2 [Chart Parser](#chartParser)\n",
        "    * 1.3 [Shift Reduce Parser](#srParser)\n",
        "    * 1.4 [Probabilistic Chart Parser](#pchartParser)\n",
        "  * 2. [SpaCy](#spacy)\n",
        "    * 2.1 [SpaCy Setup](#spacySetup)\n",
        "    * 2.2 [Spacy Natural Language Processing Pipeline](#spacyPipeline)\n",
        "    * 2.3 [Sentence Boundary Detection](#spacySentence)\n",
        "    * 2.4 [Part of Speech Tagging](#spacyPOS)\n",
        "    * 2.5 [Dependency Parsing](#spacyDep)\n",
        "  * 3. [Class Exercise](#classExercise)\n",
        "  * 4. [Answers](#answers)      \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/datasci-w266/2023-summer-main/blob/master/materials/lesson_notebooks/lesson_8_Parsing.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gfh-AqbIMtEk"
      },
      "source": [
        "[Return to Top](#returnToTop)  \n",
        "<a id = 'nltk'></a>\n",
        "\n",
        "\n",
        "## 1. NLTK Parsers\n",
        "\n",
        "NLTK (Natural Language Tool Kit) is an older python library that enables the pre-neural way of doing many of the language processing tasks that we discuss in this class.  It is a good way of exploring algorithms and non-neural implementations. The [NLTK book](https://www.nltk.org/book/) is referenced in the syllabus.\n",
        "\n",
        "\n",
        "[Return to Top](#returnToTop)  \n",
        "<a id = 'nltkSetup'></a>\n",
        "\n",
        "### 1.1 NLTK set up\n",
        "\n",
        "Let's set up our environment to run the NLTK library.  It was created before the advent of neural NLP but provides a great illustration of these approaches and allows you to experiment with them.  These implementations do not require a GPU and can easily run on your laptop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "f0PrW_vywtRY"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import subprocess\n",
        "import sys\n",
        "import nltk\n",
        "from nltk import Nonterminal, nonterminals, Production, CFG, PCFG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1pP4Rj-ne6b"
      },
      "source": [
        "[Return to Top](#returnToTop)  \n",
        "<a id = 'chartParser'></a>\n",
        "\n",
        "### 1.2 NLTK Chart parser\n",
        "\n",
        "Recall that a [chart parser](https://www.nltk.org/howto/parse.html) requires some way of prioritizing production rules.  This can be done with a context free grammar.  Here's an example of such a grammar that deals with the wonderfully ambiguous line \"I shot an elephant in my pajamas\".  The prepositional phrase \"in my pajamas\" can be attached to the verb  \"shot\" meaning I was wearing pajamas or attached to the non \"elephant\" meaning the elephant was wearing my pajamas. Both parses are equally valid gramatically speaking even though the attachment to the verb shot is the more probable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxW2Tjtbpt0a"
      },
      "source": [
        "First we define our context free grammar.  A real full grammar for English would be significantly larger."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xUwtEnMfwzly"
      },
      "outputs": [],
      "source": [
        "groucho_grammar = nltk.CFG.fromstring(\"\"\"\n",
        " S -> NP VP\n",
        " PP -> P NP\n",
        " NP -> Det N | Det N PP | 'I'\n",
        " VP -> V NP | VP PP\n",
        " Det -> 'an' | 'my'\n",
        " N -> 'elephant' | 'pajamas'\n",
        " V -> 'shot'\n",
        " P -> 'in'\n",
        " \"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOk_aA_Ap9pn"
      },
      "source": [
        "Now we can feed our grammar and sentence in to the chart parser and generate some parses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dh69Ftswzop",
        "outputId": "68135eee-58bc-4193-ab79-dc7921772959"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     S                                       \n",
            "  ___|______________                          \n",
            " |                  VP                       \n",
            " |         _________|__________               \n",
            " |        VP                   PP            \n",
            " |    ____|___              ___|___           \n",
            " |   |        NP           |       NP        \n",
            " |   |     ___|_____       |    ___|_____     \n",
            " NP  V   Det        N      P  Det        N   \n",
            " |   |    |         |      |   |         |    \n",
            " I  shot  an     elephant  in  my     pajamas\n",
            "\n",
            "     S                                   \n",
            "  ___|__________                          \n",
            " |              VP                       \n",
            " |    __________|______                   \n",
            " |   |                 NP                \n",
            " |   |     ____________|___               \n",
            " |   |    |     |          PP            \n",
            " |   |    |     |       ___|___           \n",
            " |   |    |     |      |       NP        \n",
            " |   |    |     |      |    ___|_____     \n",
            " NP  V   Det    N      P  Det        N   \n",
            " |   |    |     |      |   |         |    \n",
            " I  shot  an elephant  in  my     pajamas\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sent = ['I', 'shot', 'an', 'elephant', 'in', 'my', 'pajamas']\n",
        "parser = nltk.ChartParser(groucho_grammar)\n",
        "for tree in parser.parse(sent):\n",
        "     tree.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCpUUCgwqLlh"
      },
      "source": [
        "Note the parser includes trees for both prepositional attachment possibilities because both parses are equally valid given our grammar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAkUoNcmOKWu"
      },
      "source": [
        "[Return to Top](#returnToTop)  \n",
        "<a id = 'srParser'></a>\n",
        "\n",
        "### 1.3 NLTK Shift Reduce Parser Example\n",
        "\n",
        "Let's try NLTK's simple shift reduce parser.  This is a parser that uses a grammar we provide and generates a constituency parse that corresponds to our grammar.  As such it can only work as well as the grammar we provide.  If you alter the input sentence to inpclude words not in the grammar you will generte an exception."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pL1d3ep_wzsA"
      },
      "outputs": [],
      "source": [
        "#shift reduce parser example\n",
        "from nltk.grammar import Nonterminal\n",
        "from nltk.parse.api import ParserI\n",
        "from nltk.tree import Tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeXjtkwps45O"
      },
      "source": [
        "Now let's run the shift reduce parser.  The buffer is loaded with all of the words in our sentence.  On the left, before the square bracket is a letter **S** or **R**.  **S** means the parser picks the Shift command and move a token from the buffer to the stack.  **R** means it chooses the reduce command so swaps out a word for a label based on the grammar.  The parser runs until the buffer is empty."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnO6Rr9awzuI",
        "outputId": "a3cb3da1-4572-48a1-ce8e-ae93cd7db3c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsing 'I shot an elephant in my pajamas'\n",
            "    [ * I shot an elephant in my pajamas]\n",
            "  S [ 'I' * shot an elephant in my pajamas]\n",
            "  R [ NP * shot an elephant in my pajamas]\n",
            "  S [ NP 'shot' * an elephant in my pajamas]\n",
            "  R [ NP V * an elephant in my pajamas]\n",
            "  S [ NP V 'an' * elephant in my pajamas]\n",
            "  R [ NP V Det * elephant in my pajamas]\n",
            "  S [ NP V Det 'elephant' * in my pajamas]\n",
            "  R [ NP V Det N * in my pajamas]\n",
            "  R [ NP V NP * in my pajamas]\n",
            "  R [ NP VP * in my pajamas]\n",
            "  R [ S * in my pajamas]\n",
            "  S [ S 'in' * my pajamas]\n",
            "  R [ S P * my pajamas]\n",
            "  S [ S P 'my' * pajamas]\n",
            "  R [ S P Det * pajamas]\n",
            "  S [ S P Det 'pajamas' * ]\n",
            "  R [ S P Det N * ]\n",
            "  R [ S P NP * ]\n",
            "  R [ S PP * ]\n"
          ]
        }
      ],
      "source": [
        "parser = nltk.parse.ShiftReduceParser(groucho_grammar, trace=2)\n",
        "for p in parser.parse(sent):\n",
        "    print(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNTSyqq_5aHI"
      },
      "source": [
        "Note the shift reduce parser doesn't produce a single constituency parse with an S at the top of the tree."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifm3qbtU5aD8"
      },
      "source": [
        "[Return to Top](#returnToTop)  \n",
        "<a id = 'pchartParser'></a>\n",
        "\n",
        "### 1.4 NLTK Probabilistic Chart Parser\n",
        "\n",
        "Here is a probabilistic chart parser where we define a grammar and associate a probability with each of the productions.  We can use this to generate a joint probability for each parse of the sentence.\n",
        "\n",
        "First, we define our grammar and associate probabilities with each production.  Note that the probabilities associated with the left hand rule **VP** add up to one.  There is a vey low probability associated with attaching a prepositional phrase (PP) to a verb phrase (VP)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_Oo3PACh57wD"
      },
      "outputs": [],
      "source": [
        "from nltk.parse import pchart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WnnCaeSU5ZQK"
      },
      "outputs": [],
      "source": [
        "toy_pcfg2 = PCFG.fromstring(\"\"\"\n",
        "     S    -> NP VP         [1.0]\n",
        "     VP   -> V NP          [.59]\n",
        "     VP   -> V             [.40]\n",
        "     VP   -> VP PP         [.01]\n",
        "     NP   -> Det N         [.41]\n",
        "     NP   -> Name          [.28]\n",
        "     NP   -> NP PP         [.31]\n",
        "     PP   -> P NP          [1.0]\n",
        "     V    -> 'saw'         [.21]\n",
        "     V    -> 'shot'        [.51]\n",
        "     V    -> 'ran'         [.28]\n",
        "     N    -> 'boy'         [.11]\n",
        "     N    -> 'pajamas'     [.12]\n",
        "     N    -> 'table'       [.13]\n",
        "     N    -> 'telescope'   [.14]\n",
        "     N    -> 'elephant'    [.5]\n",
        "     Name -> 'Jack'        [.32]\n",
        "     Name -> 'Bob'         [.28]\n",
        "     Name -> 'I'           [.40]\n",
        "     P    -> 'in'          [.30] \n",
        "     P    -> 'with'        [.41]\n",
        "     P    -> 'under'       [.29]\n",
        "     Det  -> 'the'         [.41]\n",
        "     Det  -> 'an'          [.31]\n",
        "     Det  -> 'my'          [.28]\n",
        "     \"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JC3FpzJD6gJe",
        "outputId": "d2ba22e3-4068-4450-cf75-d110a98d0e2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (NP (Name I))\n",
            "  (VP\n",
            "    (V shot)\n",
            "    (NP\n",
            "      (NP (Det an) (N elephant))\n",
            "      (PP (P in) (NP (Det my) (N pajamas)))))) (p=2.74386e-06)\n",
            "(S\n",
            "  (NP (Name I))\n",
            "  (VP\n",
            "    (VP (V shot) (NP (Det an) (N elephant)))\n",
            "    (PP (P in) (NP (Det my) (N pajamas))))) (p=8.85116e-08)\n"
          ]
        }
      ],
      "source": [
        "sent = ['I', 'shot', 'an', 'elephant', 'in', 'my', 'pajamas']\n",
        "grammar = toy_pcfg2\n",
        "parser = pchart.InsideChartParser(grammar)\n",
        "for t in parser.parse(sent):\n",
        "    print(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5NAuPNPOWp3"
      },
      "source": [
        "[Return to Top](#returnToTop)  \n",
        "<a id = 'spacy'></a>\n",
        "\n",
        "## 2. SpaCy for Language Processing\n",
        "\n",
        "Let's set up our environment to run the current version of [SpaCy](https://spacy.io) and feed it a small snippet of text to see what it can do.  \n",
        "\n",
        "SpaCy is an open source industrial strength NLP engine that can perform multiple functions out of the box. It strikes a good balance between speed of processing and accuracy of predictions.  It comes with a number of different language models trained on the [OntoNotes5](https://catalog.ldc.upenn.edu/LDC2013T19) data set.  This means that it is already trained to do part of speech tagging and dependency parsing.  It can also be trained to do classification and a number of other tasks in the standard NLP stack.  It is very fast.  It can be a handy way of analyzing some text for exploratory data analysis. Another use is annotating some text to then create a labelled training set that you use to train up your own model independent of spaCy.\n",
        "\n",
        "SpaCy uses a combination of techniques including embeddings and convolutional neural nets to genearate the output we see. Newer versions (> 2.1) are able to interact with pre-trained transformers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLAB_vCRTOGP"
      },
      "source": [
        "[Return to Top](#returnToTop)  \n",
        "<a id = 'spacySetup'></a>\n",
        "\n",
        "### 2.1 SpaCy Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emk0eFYbwzyz",
        "outputId": "594d62b7-0906-411d-a24c-26adf56ba9b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 3.4.1 requires spacy<3.5.0,>=3.4.0, but you have spacy 3.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip -q install -U spacy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_EnoqmUwz1b",
        "outputId": "8783ff2c-a934-4b98-df77-ca0768600e36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting spacy-lookups-data\n",
            "  Downloading spacy_lookups_data-1.0.3-py2.py3-none-any.whl (98.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.5/98.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy-lookups-data) (57.4.0)\n",
            "Installing collected packages: spacy-lookups-data\n",
            "Successfully installed spacy-lookups-data-1.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install -U spacy-lookups-data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebg7KXskwz5G",
        "outputId": "88e04876-3314-4286-ab07-c94ede0e4b7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.5.0\n",
            "1.3.5\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "\n",
        "print(spacy.__version__)\n",
        "print(pd.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FU2Cb3JGQhZE"
      },
      "source": [
        "#### Pre-trained Language Models for SpaCy\n",
        "\n",
        "SpaCy has also been pre-trained on multiple languages.  When using it you need to select and load a specific language model.\n",
        "\n",
        "Make sure you first download a language model then load it into SpaCy. We're selecting English via a small model which gives us access to a wide variety of functionality.  There are many other options and other languages. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6CSDp0B5wz_n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7d88418-fd23-47e4-fb8f-404f8950a4e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/util.py:877: UserWarning: [W095] Model 'en_core_web_sm' (3.4.1) was trained with spaCy v3.4 and may not be 100% compatible with the current version (3.5.0). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        }
      ],
      "source": [
        "#load an english model\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZjidc5bR4fg"
      },
      "source": [
        "[Return to Top](#returnToTop)  \n",
        "<a id = 'spacyPipeline'></a>\n",
        "\n",
        "### 2.2 SpaCy Natural Language Processing Pipeline\n",
        "When you invoke spaCy with some input text it generates a set of objects.  spaCy wants to process \"document\" like objects. This document can be one sentence or can be many sentences.  You provide the text and spaCy runs the nlp function which returns a Doc object.  That Doc object contains a list of Token objects each of which is associated with a set of annotations.  Many examples below are just about harvesting the labels associated with each token after the processing of the document in the Doc object. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "uT-xcQihR31j",
        "outputId": "78003f6a-2286-412c-cc0c-64d5e3c4060c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The first word is: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "doc = nlp(u\"This is a sentence that we want to process.\")\n",
        "\n",
        "print(\"The first word is: \") \n",
        "doc[0].text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eom49P2IQ1KD"
      },
      "source": [
        "[Return to Top](#returnToTop)  \n",
        "<a id = 'spacySentence'></a>\n",
        "\n",
        "### 2.3 Sentence Boundary Detection\n",
        "\n",
        "Let's demonstrate some of the capabilities built in to the SpaCy language processing pipeline.  One problem we sometimes have to deal with is sentence boundayr detection.  We want to process a sequence of words as a unit like a sentence.  We might then want to feed individual sentences in to some SpaCy process.\n",
        "\n",
        "Let's see if we can convert these five lines of text into the three sentences they contain.  We include the tricky 'U.S.' in our lines to see if the bounadry detector can handle more complex cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9T8tvXtw0Cp",
        "outputId": "ba3ff4b7-b860-4ce1-c58b-d0c565985cce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence boundary detection is actually a pretty hard problem.  \n",
            "Great advances have been made in the U.S. in the past decade.\n",
            "New neural nets like a CNN can help improve results on this classification task.\n"
          ]
        }
      ],
      "source": [
        "#sentence detection\n",
        "# Given an input block of text, identify where the sentences end.\n",
        "\n",
        "about_text = ('Sentence boundary detection is actually'\n",
        "              ' a pretty hard problem.  Great advances'\n",
        "              ' have been made in the U.S. in the'\n",
        "              ' past decade. New neural nets'\n",
        "              ' like a CNN can help improve results on this classification task.')\n",
        "about_doc = nlp(about_text)\n",
        "sentences = list(about_doc.sents)\n",
        "#len(sentences)\n",
        " \n",
        "#now print out the three sentences\n",
        "for sentence in sentences:\n",
        "    print (sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkZ3iyqIZM8z"
      },
      "source": [
        "[Return to Top](#returnToTop)  \n",
        "<a id = 'spacyPOS'></a>\n",
        "\n",
        "### 2.4 Part of Speech Tagging\n",
        "Part of speech tagging can also be very valuable.  Tagging words can allow you to quickly distinguish \"things\" from \"actions\" or \"events.\" \n",
        "SpaCy has several different tags to display related to part of speech as shown below.  First, we'll just print out the tags.  Second we'll take the output and display it in a table using pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBnQls-xw0J4",
        "outputId": "c8ed24b2-592f-449b-ad06-add8e668adf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence NN NOUN noun, singular or mass\n",
            "boundary JJ ADJ adjective (English), other noun-modifier (Chinese)\n",
            "detection NN NOUN noun, singular or mass\n",
            "is VBZ AUX verb, 3rd person singular present\n",
            "actually RB ADV adverb\n",
            "a DT DET determiner\n",
            "pretty RB ADV adverb\n",
            "hard JJ ADJ adjective (English), other noun-modifier (Chinese)\n",
            "problem NN NOUN noun, singular or mass\n",
            ". . PUNCT punctuation mark, sentence closer\n",
            "  _SP SPACE whitespace\n",
            "Great JJ ADJ adjective (English), other noun-modifier (Chinese)\n",
            "advances NNS NOUN noun, plural\n",
            "have VBP AUX verb, non-3rd person singular present\n",
            "been VBN AUX verb, past participle\n",
            "made VBN VERB verb, past participle\n",
            "in IN ADP conjunction, subordinating or preposition\n",
            "the DT DET determiner\n",
            "U.S. NNP PROPN noun, proper singular\n",
            "in IN ADP conjunction, subordinating or preposition\n",
            "the DT DET determiner\n",
            "past JJ ADJ adjective (English), other noun-modifier (Chinese)\n",
            "decade NN NOUN noun, singular or mass\n",
            ". . PUNCT punctuation mark, sentence closer\n",
            "New JJ ADJ adjective (English), other noun-modifier (Chinese)\n",
            "neural JJ ADJ adjective (English), other noun-modifier (Chinese)\n",
            "nets NNS NOUN noun, plural\n",
            "like IN ADP conjunction, subordinating or preposition\n",
            "a DT DET determiner\n",
            "CNN NNP PROPN noun, proper singular\n",
            "can MD AUX verb, modal auxiliary\n",
            "help VB VERB verb, base form\n",
            "improve VB VERB verb, base form\n",
            "results NNS NOUN noun, plural\n",
            "on IN ADP conjunction, subordinating or preposition\n",
            "this DT DET determiner\n",
            "classification NN NOUN noun, singular or mass\n",
            "task NN NOUN noun, singular or mass\n",
            ". . PUNCT punctuation mark, sentence closer\n"
          ]
        }
      ],
      "source": [
        "#POS with unpretty print\n",
        "\n",
        "for token in about_doc:\n",
        "    print (token, token.tag_, token.pos_, spacy.explain(token.tag_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMPNJS2SZtnz"
      },
      "source": [
        "Let's process that input from the variable *about_doc* and show the results of POS tagging the three sentences it contains.  We'll take that output and display it in a table with columns for the word, it's POS tag, a higher level syntactic description, and an explanation for the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OM_SSSyK2I1v",
        "outputId": "dfaa31d0-9960-41c2-d78e-31997141a0c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              text  tag    pos  \\\n",
              "0         Sentence   NN   NOUN   \n",
              "1         boundary   JJ    ADJ   \n",
              "2        detection   NN   NOUN   \n",
              "3               is  VBZ    AUX   \n",
              "4         actually   RB    ADV   \n",
              "5                a   DT    DET   \n",
              "6           pretty   RB    ADV   \n",
              "7             hard   JJ    ADJ   \n",
              "8          problem   NN   NOUN   \n",
              "9                .    .  PUNCT   \n",
              "10                  _SP  SPACE   \n",
              "11           Great   JJ    ADJ   \n",
              "12        advances  NNS   NOUN   \n",
              "13            have  VBP    AUX   \n",
              "14            been  VBN    AUX   \n",
              "15            made  VBN   VERB   \n",
              "16              in   IN    ADP   \n",
              "17             the   DT    DET   \n",
              "18            U.S.  NNP  PROPN   \n",
              "19              in   IN    ADP   \n",
              "20             the   DT    DET   \n",
              "21            past   JJ    ADJ   \n",
              "22          decade   NN   NOUN   \n",
              "23               .    .  PUNCT   \n",
              "24             New   JJ    ADJ   \n",
              "25          neural   JJ    ADJ   \n",
              "26            nets  NNS   NOUN   \n",
              "27            like   IN    ADP   \n",
              "28               a   DT    DET   \n",
              "29             CNN  NNP  PROPN   \n",
              "30             can   MD    AUX   \n",
              "31            help   VB   VERB   \n",
              "32         improve   VB   VERB   \n",
              "33         results  NNS   NOUN   \n",
              "34              on   IN    ADP   \n",
              "35            this   DT    DET   \n",
              "36  classification   NN   NOUN   \n",
              "37            task   NN   NOUN   \n",
              "38               .    .  PUNCT   \n",
              "\n",
              "                                              explain  \n",
              "0                              noun, singular or mass  \n",
              "1   adjective (English), other noun-modifier (Chin...  \n",
              "2                              noun, singular or mass  \n",
              "3                   verb, 3rd person singular present  \n",
              "4                                              adverb  \n",
              "5                                          determiner  \n",
              "6                                              adverb  \n",
              "7   adjective (English), other noun-modifier (Chin...  \n",
              "8                              noun, singular or mass  \n",
              "9                   punctuation mark, sentence closer  \n",
              "10                                         whitespace  \n",
              "11  adjective (English), other noun-modifier (Chin...  \n",
              "12                                       noun, plural  \n",
              "13              verb, non-3rd person singular present  \n",
              "14                              verb, past participle  \n",
              "15                              verb, past participle  \n",
              "16          conjunction, subordinating or preposition  \n",
              "17                                         determiner  \n",
              "18                              noun, proper singular  \n",
              "19          conjunction, subordinating or preposition  \n",
              "20                                         determiner  \n",
              "21  adjective (English), other noun-modifier (Chin...  \n",
              "22                             noun, singular or mass  \n",
              "23                  punctuation mark, sentence closer  \n",
              "24  adjective (English), other noun-modifier (Chin...  \n",
              "25  adjective (English), other noun-modifier (Chin...  \n",
              "26                                       noun, plural  \n",
              "27          conjunction, subordinating or preposition  \n",
              "28                                         determiner  \n",
              "29                              noun, proper singular  \n",
              "30                              verb, modal auxiliary  \n",
              "31                                    verb, base form  \n",
              "32                                    verb, base form  \n",
              "33                                       noun, plural  \n",
              "34          conjunction, subordinating or preposition  \n",
              "35                                         determiner  \n",
              "36                             noun, singular or mass  \n",
              "37                             noun, singular or mass  \n",
              "38                  punctuation mark, sentence closer  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-57557c3a-b96c-45d1-8823-1e55ca547074\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tag</th>\n",
              "      <th>pos</th>\n",
              "      <th>explain</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence</td>\n",
              "      <td>NN</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>noun, singular or mass</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>boundary</td>\n",
              "      <td>JJ</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>adjective (English), other noun-modifier (Chin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>detection</td>\n",
              "      <td>NN</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>noun, singular or mass</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>is</td>\n",
              "      <td>VBZ</td>\n",
              "      <td>AUX</td>\n",
              "      <td>verb, 3rd person singular present</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>actually</td>\n",
              "      <td>RB</td>\n",
              "      <td>ADV</td>\n",
              "      <td>adverb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>a</td>\n",
              "      <td>DT</td>\n",
              "      <td>DET</td>\n",
              "      <td>determiner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>pretty</td>\n",
              "      <td>RB</td>\n",
              "      <td>ADV</td>\n",
              "      <td>adverb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>hard</td>\n",
              "      <td>JJ</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>adjective (English), other noun-modifier (Chin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>problem</td>\n",
              "      <td>NN</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>noun, singular or mass</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>punctuation mark, sentence closer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td></td>\n",
              "      <td>_SP</td>\n",
              "      <td>SPACE</td>\n",
              "      <td>whitespace</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Great</td>\n",
              "      <td>JJ</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>adjective (English), other noun-modifier (Chin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>advances</td>\n",
              "      <td>NNS</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>noun, plural</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>AUX</td>\n",
              "      <td>verb, non-3rd person singular present</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>been</td>\n",
              "      <td>VBN</td>\n",
              "      <td>AUX</td>\n",
              "      <td>verb, past participle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>made</td>\n",
              "      <td>VBN</td>\n",
              "      <td>VERB</td>\n",
              "      <td>verb, past participle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>in</td>\n",
              "      <td>IN</td>\n",
              "      <td>ADP</td>\n",
              "      <td>conjunction, subordinating or preposition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>DET</td>\n",
              "      <td>determiner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>U.S.</td>\n",
              "      <td>NNP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>noun, proper singular</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>in</td>\n",
              "      <td>IN</td>\n",
              "      <td>ADP</td>\n",
              "      <td>conjunction, subordinating or preposition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>DET</td>\n",
              "      <td>determiner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>past</td>\n",
              "      <td>JJ</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>adjective (English), other noun-modifier (Chin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>decade</td>\n",
              "      <td>NN</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>noun, singular or mass</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>punctuation mark, sentence closer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>New</td>\n",
              "      <td>JJ</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>adjective (English), other noun-modifier (Chin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>neural</td>\n",
              "      <td>JJ</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>adjective (English), other noun-modifier (Chin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>nets</td>\n",
              "      <td>NNS</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>noun, plural</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>like</td>\n",
              "      <td>IN</td>\n",
              "      <td>ADP</td>\n",
              "      <td>conjunction, subordinating or preposition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>a</td>\n",
              "      <td>DT</td>\n",
              "      <td>DET</td>\n",
              "      <td>determiner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>CNN</td>\n",
              "      <td>NNP</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>noun, proper singular</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>can</td>\n",
              "      <td>MD</td>\n",
              "      <td>AUX</td>\n",
              "      <td>verb, modal auxiliary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>help</td>\n",
              "      <td>VB</td>\n",
              "      <td>VERB</td>\n",
              "      <td>verb, base form</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>improve</td>\n",
              "      <td>VB</td>\n",
              "      <td>VERB</td>\n",
              "      <td>verb, base form</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>results</td>\n",
              "      <td>NNS</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>noun, plural</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>on</td>\n",
              "      <td>IN</td>\n",
              "      <td>ADP</td>\n",
              "      <td>conjunction, subordinating or preposition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>this</td>\n",
              "      <td>DT</td>\n",
              "      <td>DET</td>\n",
              "      <td>determiner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>classification</td>\n",
              "      <td>NN</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>noun, singular or mass</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>task</td>\n",
              "      <td>NN</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>noun, singular or mass</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>punctuation mark, sentence closer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57557c3a-b96c-45d1-8823-1e55ca547074')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-57557c3a-b96c-45d1-8823-1e55ca547074 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-57557c3a-b96c-45d1-8823-1e55ca547074');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "#POS\n",
        "#capturing the output in a pandas dataframe makes it easier to view\n",
        "dpos = pd.DataFrame()\n",
        "dpos['text'] = [token.text for token in about_doc]\n",
        "dpos['tag'] = [token.tag_ for token in about_doc]\n",
        "dpos['pos'] = [token.pos_ for token in about_doc]\n",
        "dpos['explain'] = [spacy.explain(token.tag_) for token in about_doc]\n",
        "\n",
        "dpos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ED3q7VvcCN6"
      },
      "source": [
        "[Return to Top](#returnToTop)  \n",
        "<a id = 'spacyDep'></a>\n",
        "\n",
        "### 2.5 Dependency Parsing\n",
        "\n",
        "Now let's test SpaCy's ability to generate dependency parse trees. SpaCy has been pre-trained on a number of different tasks, like T5. Spacy performs multiple analyses simultaneously so we can walk over the list of input tokens and simply call up the labels assigned to each token.\n",
        "\n",
        "This approach can be difficult for a human to read.  Sometimes the data can be used for training other models or for exploratory data analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRPjVaYc2Iv7",
        "outputId": "19b7d3a4-9f11-41fd-c8f0-9c6ff3c70df5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Students NNS learning nsubj\n",
            "are VBP learning aux\n",
            "learning VBG learning ROOT\n",
            "Natural NNP Language compound\n",
            "Language NNP Processing compound\n",
            "Processing NNP learning dobj\n",
            "in IN learning prep\n",
            "the DT class det\n",
            "W266 JJ class amod\n",
            "class NN in pobj\n",
            ". . learning punct\n"
          ]
        }
      ],
      "source": [
        "#dependency parsing\n",
        "w266_text = 'Students are learning Natural Language Processing in the W266 class.'\n",
        "w266_doc = nlp(w266_text)\n",
        "for token in w266_doc:\n",
        "    print (token.text, token.tag_, token.head.text, token.dep_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dFgdZoGmzSl"
      },
      "source": [
        "Lets capture the output and put it into a pandas dataframe for easier consumption."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "IL_s-17f2IuC",
        "outputId": "28509e66-433b-4e7b-a4db-6e7327ea887d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          text       lemma  is_punctuation  is_space  shape part_of_speech  \\\n",
              "0     Students     student           False     False  Xxxxx           NOUN   \n",
              "1          are          be           False     False    xxx            AUX   \n",
              "2     learning       learn           False     False   xxxx           VERB   \n",
              "3      Natural     Natural           False     False  Xxxxx          PROPN   \n",
              "4     Language    Language           False     False  Xxxxx          PROPN   \n",
              "5   Processing  Processing           False     False  Xxxxx          PROPN   \n",
              "6           in          in           False     False     xx            ADP   \n",
              "7          the         the           False     False    xxx            DET   \n",
              "8         W266        w266           False     False   Xddd            ADJ   \n",
              "9        class       class           False     False   xxxx           NOUN   \n",
              "10           .           .            True     False      .          PUNCT   \n",
              "\n",
              "   pos_tag        head       dep  \n",
              "0      NNS    learning     nsubj  \n",
              "1      VBP    learning       aux  \n",
              "2      VBG    learning      ROOT  \n",
              "3      NNP    Language  compound  \n",
              "4      NNP  Processing  compound  \n",
              "5      NNP    learning      dobj  \n",
              "6       IN    learning      prep  \n",
              "7       DT       class       det  \n",
              "8       JJ       class      amod  \n",
              "9       NN          in      pobj  \n",
              "10       .    learning     punct  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d3fc9391-a4d0-4e2e-bbb3-cd1ac43eafce\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>lemma</th>\n",
              "      <th>is_punctuation</th>\n",
              "      <th>is_space</th>\n",
              "      <th>shape</th>\n",
              "      <th>part_of_speech</th>\n",
              "      <th>pos_tag</th>\n",
              "      <th>head</th>\n",
              "      <th>dep</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Students</td>\n",
              "      <td>student</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Xxxxx</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>NNS</td>\n",
              "      <td>learning</td>\n",
              "      <td>nsubj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>are</td>\n",
              "      <td>be</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>xxx</td>\n",
              "      <td>AUX</td>\n",
              "      <td>VBP</td>\n",
              "      <td>learning</td>\n",
              "      <td>aux</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>learning</td>\n",
              "      <td>learn</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>xxxx</td>\n",
              "      <td>VERB</td>\n",
              "      <td>VBG</td>\n",
              "      <td>learning</td>\n",
              "      <td>ROOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Natural</td>\n",
              "      <td>Natural</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Xxxxx</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>NNP</td>\n",
              "      <td>Language</td>\n",
              "      <td>compound</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Language</td>\n",
              "      <td>Language</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Xxxxx</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>NNP</td>\n",
              "      <td>Processing</td>\n",
              "      <td>compound</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Processing</td>\n",
              "      <td>Processing</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Xxxxx</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>NNP</td>\n",
              "      <td>learning</td>\n",
              "      <td>dobj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>in</td>\n",
              "      <td>in</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>xx</td>\n",
              "      <td>ADP</td>\n",
              "      <td>IN</td>\n",
              "      <td>learning</td>\n",
              "      <td>prep</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>xxx</td>\n",
              "      <td>DET</td>\n",
              "      <td>DT</td>\n",
              "      <td>class</td>\n",
              "      <td>det</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>W266</td>\n",
              "      <td>w266</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Xddd</td>\n",
              "      <td>ADJ</td>\n",
              "      <td>JJ</td>\n",
              "      <td>class</td>\n",
              "      <td>amod</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>class</td>\n",
              "      <td>class</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>xxxx</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>NN</td>\n",
              "      <td>in</td>\n",
              "      <td>pobj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>.</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>.</td>\n",
              "      <td>learning</td>\n",
              "      <td>punct</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d3fc9391-a4d0-4e2e-bbb3-cd1ac43eafce')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d3fc9391-a4d0-4e2e-bbb3-cd1ac43eafce button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d3fc9391-a4d0-4e2e-bbb3-cd1ac43eafce');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "#if you capture the tags in a dataframe you can then perform additional \n",
        "#operations like counting and filtering and searching\n",
        "\n",
        "df = pd.DataFrame()\n",
        "df['text'] = [token.text for token in w266_doc]\n",
        "df['lemma'] = [token.lemma_ for token in w266_doc]\n",
        "df['is_punctuation'] = [token.is_punct for token in w266_doc]\n",
        "df['is_space'] = [token.is_space for token in w266_doc]\n",
        "df['shape'] = [token.shape_ for token in w266_doc]\n",
        "df['part_of_speech'] = [token.pos_ for token in w266_doc]\n",
        "df['pos_tag'] = [token.tag_ for token in w266_doc]\n",
        "df['head'] = [token.head.text for token in w266_doc] \n",
        "df['dep'] = [token.dep_ for token in w266_doc]\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89zO-O0ZjeOt"
      },
      "source": [
        "The dependency tree is a list of arcs and labels.  These are shown in the final two columns.  The 'head' column indicates the word from which the incoming arc originates and the 'dep' column contains the label associated with that tag.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfg4bwMxi_CH"
      },
      "source": [
        "We can also visualize the dependency tree with the call to 'displacy.render' and then displaying the resulting HTML code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "9PtOkFt52Ig7"
      },
      "outputs": [],
      "source": [
        "from spacy import displacy\n",
        "from IPython.core.display import HTML\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "vAbQGRGz2IdB"
      },
      "outputs": [],
      "source": [
        "html = displacy.render(w266_doc, style=\"dep\")\n",
        "#print(html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "zF6wuFoM2Iaq",
        "outputId": "f6e1c674-dfb1-4c20-f7ad-74f797050955"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"9177bb65b03049f3bcb318eec8039f0d-0\" class=\"displacy\" width=\"1800\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Students</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">are</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">learning</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">Natural</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">Language</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">Processing</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">in</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">W266</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">class.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-9177bb65b03049f3bcb318eec8039f0d-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,89.5 395.0,89.5 395.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-9177bb65b03049f3bcb318eec8039f0d-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-9177bb65b03049f3bcb318eec8039f0d-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-9177bb65b03049f3bcb318eec8039f0d-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-9177bb65b03049f3bcb318eec8039f0d-0-2\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-9177bb65b03049f3bcb318eec8039f0d-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-9177bb65b03049f3bcb318eec8039f0d-0-3\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-9177bb65b03049f3bcb318eec8039f0d-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M770,266.5 L762,254.5 778,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-9177bb65b03049f3bcb318eec8039f0d-0-4\" stroke-width=\"2px\" d=\"M420,264.5 C420,89.5 920.0,89.5 920.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-9177bb65b03049f3bcb318eec8039f0d-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M920.0,266.5 L928.0,254.5 912.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-9177bb65b03049f3bcb318eec8039f0d-0-5\" stroke-width=\"2px\" d=\"M420,264.5 C420,2.0 1100.0,2.0 1100.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-9177bb65b03049f3bcb318eec8039f0d-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1100.0,266.5 L1108.0,254.5 1092.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-9177bb65b03049f3bcb318eec8039f0d-0-6\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,89.5 1620.0,89.5 1620.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-9177bb65b03049f3bcb318eec8039f0d-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1295,266.5 L1287,254.5 1303,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-9177bb65b03049f3bcb318eec8039f0d-0-7\" stroke-width=\"2px\" d=\"M1470,264.5 C1470,177.0 1615.0,177.0 1615.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-9177bb65b03049f3bcb318eec8039f0d-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1470,266.5 L1462,254.5 1478,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-9177bb65b03049f3bcb318eec8039f0d-0-8\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,2.0 1625.0,2.0 1625.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-9177bb65b03049f3bcb318eec8039f0d-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1625.0,266.5 L1633.0,254.5 1617.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "HTML(html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6Gh1U-ynIbT"
      },
      "source": [
        "We'll look at other SpaCy capabilities in later classes.\n",
        "\n",
        "[Return to Top](#returnToTop)  \n",
        "<a id = 'classExercise'></a>\n",
        "\n",
        "## 3. Class Exercise\n",
        "\n",
        "Try submitting sentences to the SpaCY dependency parser to see how well it does and where it begins to break down.\n",
        "\n",
        "Here are a number of \"garden path\" sentences where words at the end modify the meaning of words toward the front and alter the correct parts of speech.  You can submit these sentences or come up with your own."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvJEtJ_kTOGZ",
        "outputId": "dd52a398-99c2-4cf7-ca3f-f3ef40e6b2c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The DT man det\n",
            "blind JJ man amod\n",
            "man NN picked nsubj\n",
            "picked VBD picked ROOT\n",
            "up RP picked prt\n",
            "the DT hammer det\n",
            "hammer NN picked dobj\n",
            "and CC picked cc\n",
            "saw VBD picked conj\n",
            ". . picked punct\n"
          ]
        }
      ],
      "source": [
        "#w266_text = 'The complex houses married and single students and their families.'\n",
        "w266_text = 'The blind man picked up the hammer and saw.'\n",
        "#w266_text = 'The woman with the dog that had the parasol was brown.'\n",
        "#w266_text = 'The old man the boat.'\n",
        "#w266_text = 'Time flies like an arrow, fruit flies like a banana.'\n",
        "#w266_text = 'Everyone must learn to parse long multi-clausal sentences because they teach us about the intricacies of grammar.'\n",
        "w266_doc = nlp(w266_text)\n",
        "for token in w266_doc:\n",
        "    print (token.text, token.tag_, token.head.text, token.dep_)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "html = displacy.render(w266_doc, style=\"dep\")\n",
        "HTML(html)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "-2af98SEU5Wi",
        "outputId": "1b3e352d-24ce-4bd6-f373-e4d0c4ed343b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"560d15cb9a0f467891ae1f1733c6b831-0\" class=\"displacy\" width=\"1625\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">blind</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">man</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">picked</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">up</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">hammer</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">and</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">CCONJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">saw.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-560d15cb9a0f467891ae1f1733c6b831-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,177.0 390.0,177.0 390.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-560d15cb9a0f467891ae1f1733c6b831-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-560d15cb9a0f467891ae1f1733c6b831-0-1\" stroke-width=\"2px\" d=\"M245,352.0 C245,264.5 385.0,264.5 385.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-560d15cb9a0f467891ae1f1733c6b831-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,354.0 L237,342.0 253,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-560d15cb9a0f467891ae1f1733c6b831-0-2\" stroke-width=\"2px\" d=\"M420,352.0 C420,264.5 560.0,264.5 560.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-560d15cb9a0f467891ae1f1733c6b831-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M420,354.0 L412,342.0 428,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-560d15cb9a0f467891ae1f1733c6b831-0-3\" stroke-width=\"2px\" d=\"M595,352.0 C595,264.5 735.0,264.5 735.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-560d15cb9a0f467891ae1f1733c6b831-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prt</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M735.0,354.0 L743.0,342.0 727.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-560d15cb9a0f467891ae1f1733c6b831-0-4\" stroke-width=\"2px\" d=\"M945,352.0 C945,264.5 1085.0,264.5 1085.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-560d15cb9a0f467891ae1f1733c6b831-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M945,354.0 L937,342.0 953,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-560d15cb9a0f467891ae1f1733c6b831-0-5\" stroke-width=\"2px\" d=\"M595,352.0 C595,177.0 1090.0,177.0 1090.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-560d15cb9a0f467891ae1f1733c6b831-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1090.0,354.0 L1098.0,342.0 1082.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-560d15cb9a0f467891ae1f1733c6b831-0-6\" stroke-width=\"2px\" d=\"M595,352.0 C595,89.5 1270.0,89.5 1270.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-560d15cb9a0f467891ae1f1733c6b831-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1270.0,354.0 L1278.0,342.0 1262.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-560d15cb9a0f467891ae1f1733c6b831-0-7\" stroke-width=\"2px\" d=\"M595,352.0 C595,2.0 1450.0,2.0 1450.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-560d15cb9a0f467891ae1f1733c6b831-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1450.0,354.0 L1458.0,342.0 1442.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}