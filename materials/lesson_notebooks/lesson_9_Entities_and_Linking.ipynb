{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjF4EmzwhYj_"
      },
      "source": [
        "# Lesson notebook 9 - Entities and Linking\n",
        "\n",
        "\n",
        "\n",
        "### NER and Unsupervised Relation Extraction with SpaCy\n",
        "\n",
        "We'll use SpaCy again, a pretrained open source language processing pipeline.  It provides a platform for processing text in a number of ways without having to perform any fine-tuning.\n",
        "\n",
        "We'll use it to demonstrate SpaCy's NER capabilities out of the box.  Take a look at the entities it finds.  How well do you think it performs?\n",
        "\n",
        "Then we'll use the dependency parsing capability to extract SVO triples from a set of sentences.  Again, look at how well the extraction works.\n",
        "\n",
        "You should experiment by adding multiple sentences in to the variable nnp_doc and see how well SpaCy does with your alternative sentences.\n",
        "\n",
        "\n",
        "<a id = 'returnToTop'></a>\n",
        "\n",
        "## Notebook Contents\n",
        "\n",
        "  * 1. [Setup](#spacySetup)\n",
        "  * 2. [Spacy Language Model Selection](#spacyPipeline)\n",
        "  * 3. [Named Entity Recognition](#spacyNER)\n",
        "  * 4. [Dependency Parsing for Information Extraction](#spacyDep)\n",
        "      * 4.1. [SVO Triple Extraction Example](#spacySVO)\n",
        "  * 5. [Answers](#answers)      \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/datasci-w266/2023-summer-main/blob/master/materials/lesson_notebooks/lesson_9_Entities_and_Linking.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wbk3MQ1biv37"
      },
      "source": [
        "[Return to Top](#returnToTop)  \n",
        "<a id = 'spacySetup'></a>\n",
        "\n",
        "## 1. Setup  \n",
        "\n",
        "\n",
        "Let's set up our environment to run the current version of [SpaCy](https://spacy.io) and feed it a sequence of text to see what it can do.  \n",
        "\n",
        "SpaCy is an open source industrial strength NLP engine that can perform multiple functions out of the box. It strikes a good balance between speed of processing and accuracy of predictions.  It comes with a number of different language models trained on the [OntoNotes5](https://catalog.ldc.upenn.edu/LDC2013T19) data set.  This means that it is already trained to do part of speech tagging and dependency parsing.  It can also be trained to do classification and a number of other tasks in the standard NLP stack.  It is very fast.  It can be a handy way of analyzing some text for exploratory data analysis. Another use is annotating some text to then create a labelled training set that you use to train up your own model independent of spaCy.\n",
        "\n",
        "spaCy uses a combination of techniques including embeddings and convolutional neural nets to generate the output we see.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_OqE_HpzhLNx"
      },
      "outputs": [],
      "source": [
        "!pip install -q spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkScHG0vhLRx",
        "outputId": "412cf54d-6113-41dc-b7c0-11749590178a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.5/98.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q spacy-lookups-data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9rYEr6khLT9",
        "outputId": "fbc6eefb-3960-4d14-8032-6e8bf1ce5f3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.5.3\n",
            "1.5.3\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "\n",
        "print(spacy.__version__)\n",
        "print(pd.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfVZ9IaujaWU"
      },
      "source": [
        "[Return to Top](#returnToTop)  \n",
        "<a id = 'spacyPipeline'></a>\n",
        "\n",
        "## 2. Pre-trained Language Models for SpaCy\n",
        "\n",
        "SpaCy has also been pre-trained on multiple languages.  When using it you need to select and load a specific language model.\n",
        "\n",
        "Make sure you first download a language model then load it into SpaCy. We're selecting English via the large model which gives us access to embeddings.  There are many other options and other languages.\n",
        "\n",
        "Downloading the large model can take a couple of minutes if your network is slower."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMiI2_uYhLXl",
        "outputId": "09ea3690-7c03-44d6-f144-dd077dac4a3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-02 20:17:20.856700: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-lg==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.5.0/en_core_web_lg-3.5.0-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.5.0) (3.5.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (8.1.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.10.9)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.1.3)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.5.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_lg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "McEi8IdKhLaG"
      },
      "outputs": [],
      "source": [
        "#load an english model -- the large model includes word embeddings\n",
        "nlp = spacy.load(\"en_core_web_lg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McCSNaBSl07X"
      },
      "source": [
        "[Return to Top](#returnToTop)  \n",
        "<a id = 'spacyNER'></a>\n",
        "\n",
        "## 3. Named Entity Recognition\n",
        "\n",
        "SpaCy is also trained to do some basic NER out of the box. It has been trained using OntoNotes5 so you can see the set of entity tags it uses to annotate its content. It identifies things like persons (PER), organizations (ORG), facilities (FAC), dates (DATE) and others. If those tags don't work for you, then you can train spaCy to identify different entities or use a different tag set.\n",
        "\n",
        "You can modify the nnp_doc variable below if you want to experiment with your own set of sentences to see how they work with the existing tagset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TWv_RfwhLkd",
        "outputId": "78e403ed-4cac-42ee-8768-7b73b611f91e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the afternoon 3 16 TIME Times smaller than a day\n",
            "Lincoln 39 46 ORG Companies, agencies, institutions, etc.\n",
            "Gettysburg 55 65 GPE Countries, cities, states\n",
            "The Gettysburg Address 100 122 ORG Companies, agencies, institutions, etc.\n",
            "four 134 138 CARDINAL Numerals that do not fall under another type\n",
            "seven years ago 149 164 DATE Absolute or relative dates or periods\n"
          ]
        }
      ],
      "source": [
        "#We'll use nnp_doc to demonstrate SpaCy's information extraction capability\n",
        "nnp_doc = nlp('On the afternoon of November 19, 1863, Lincoln went to Gettysburg. He gave his famous speech there. The Gettysburg Address began with four score and seven years ago.')\n",
        "#nnp_doc = nlp('The School of Information is located on the Berkeley campus of the University of California. The iSchool offers a variety of Masters degrees. Berkeley is adjacent to Oakland, Albany, and El Cerrito.')\n",
        "\n",
        "#NER example\n",
        "for ent in nnp_doc.ents:\n",
        "    print(ent.text, ent.start_char, ent.end_char,\n",
        "        ent.label_, spacy.explain(ent.label_))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note the NER parser makes some errors.  It tags Lincoln as an Organization and The Gettysburg Address as an Organization.  This is clearly wrong, but Lincoln is also ambiguous. It can refer to a larger city in Nebraska or a make of car. What happens if you add Abraham before Lincoln? That should help to disambiguagte the reference.  You could also try and fix the issue by fine-tuning the SpaCy model to teach it to prefer Lincoln as a person rather than an Organization."
      ],
      "metadata": {
        "id": "GzFqoq_pJxpH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Kpjc1uKkfOt"
      },
      "source": [
        "[Return to Top](#returnToTop)  \n",
        "<a id = 'spacyDep'></a>\n",
        "\n",
        "\n",
        "## 4. Dependency Parsing for Information Extraction\n",
        "\n",
        "As we saw last week, SpaCy performs dependency parsing right out of the box. This can be a very handy way of identifying words and the relations between them. Sometimes those relations fundamentally change the meaning of the word as in the case of negation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwFxecKGhLeI",
        "outputId": "55ea634a-8dc1-400b-bf6f-3b24f8715af9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Students NNS learning nsubj\n",
            "are VBP learning aux\n",
            "learning VBG learning ROOT\n",
            "Natural NNP Language compound\n",
            "Language NNP Processing compound\n",
            "Processing NNP learning dobj\n",
            "with IN learning prep\n",
            "transformers NNS with pobj\n",
            "in IN transformers prep\n",
            "the DT class det\n",
            "W266 NNS class compound\n",
            "class NN in pobj\n",
            ". . learning punct\n"
          ]
        }
      ],
      "source": [
        "#dependency parsing\n",
        "w266_text = 'Students are learning Natural Language Processing with transformers in the W266 class.'\n",
        "w266_doc = nlp(w266_text)\n",
        "for token in w266_doc:\n",
        "    print (token.text, token.tag_, token.head.text, token.dep_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2caTYfcr94pE"
      },
      "source": [
        "Let's capture it in a pandas data frame so it is easier to read and manipulate.  Once it's in a dataframe you can then perform additional operations like counting and filtering and searching on the content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "VbGjbEuQhLgv",
        "outputId": "35027587-8394-4aba-fae7-2ba8917e57b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            text        lemma  is_punctuation  is_space  shape part_of_speech  \\\n",
              "0       Students      student           False     False  Xxxxx           NOUN   \n",
              "1            are           be           False     False    xxx            AUX   \n",
              "2       learning        learn           False     False   xxxx           VERB   \n",
              "3        Natural      Natural           False     False  Xxxxx          PROPN   \n",
              "4       Language     Language           False     False  Xxxxx          PROPN   \n",
              "5     Processing   Processing           False     False  Xxxxx          PROPN   \n",
              "6           with         with           False     False   xxxx            ADP   \n",
              "7   transformers  transformer           False     False   xxxx           NOUN   \n",
              "8             in           in           False     False     xx            ADP   \n",
              "9            the          the           False     False    xxx            DET   \n",
              "10          W266         W266           False     False   Xddd           NOUN   \n",
              "11         class        class           False     False   xxxx           NOUN   \n",
              "12             .            .            True     False      .          PUNCT   \n",
              "\n",
              "   pos_tag          head       dep  \n",
              "0      NNS      learning     nsubj  \n",
              "1      VBP      learning       aux  \n",
              "2      VBG      learning      ROOT  \n",
              "3      NNP      Language  compound  \n",
              "4      NNP    Processing  compound  \n",
              "5      NNP      learning      dobj  \n",
              "6       IN      learning      prep  \n",
              "7      NNS          with      pobj  \n",
              "8       IN  transformers      prep  \n",
              "9       DT         class       det  \n",
              "10     NNS         class  compound  \n",
              "11      NN            in      pobj  \n",
              "12       .      learning     punct  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3f8bb793-44fb-4c44-8037-a4bf48682070\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>lemma</th>\n",
              "      <th>is_punctuation</th>\n",
              "      <th>is_space</th>\n",
              "      <th>shape</th>\n",
              "      <th>part_of_speech</th>\n",
              "      <th>pos_tag</th>\n",
              "      <th>head</th>\n",
              "      <th>dep</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Students</td>\n",
              "      <td>student</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Xxxxx</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>NNS</td>\n",
              "      <td>learning</td>\n",
              "      <td>nsubj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>are</td>\n",
              "      <td>be</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>xxx</td>\n",
              "      <td>AUX</td>\n",
              "      <td>VBP</td>\n",
              "      <td>learning</td>\n",
              "      <td>aux</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>learning</td>\n",
              "      <td>learn</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>xxxx</td>\n",
              "      <td>VERB</td>\n",
              "      <td>VBG</td>\n",
              "      <td>learning</td>\n",
              "      <td>ROOT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Natural</td>\n",
              "      <td>Natural</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Xxxxx</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>NNP</td>\n",
              "      <td>Language</td>\n",
              "      <td>compound</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Language</td>\n",
              "      <td>Language</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Xxxxx</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>NNP</td>\n",
              "      <td>Processing</td>\n",
              "      <td>compound</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Processing</td>\n",
              "      <td>Processing</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Xxxxx</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>NNP</td>\n",
              "      <td>learning</td>\n",
              "      <td>dobj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>with</td>\n",
              "      <td>with</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>xxxx</td>\n",
              "      <td>ADP</td>\n",
              "      <td>IN</td>\n",
              "      <td>learning</td>\n",
              "      <td>prep</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>transformers</td>\n",
              "      <td>transformer</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>xxxx</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>NNS</td>\n",
              "      <td>with</td>\n",
              "      <td>pobj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>in</td>\n",
              "      <td>in</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>xx</td>\n",
              "      <td>ADP</td>\n",
              "      <td>IN</td>\n",
              "      <td>transformers</td>\n",
              "      <td>prep</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>xxx</td>\n",
              "      <td>DET</td>\n",
              "      <td>DT</td>\n",
              "      <td>class</td>\n",
              "      <td>det</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>W266</td>\n",
              "      <td>W266</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Xddd</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>NNS</td>\n",
              "      <td>class</td>\n",
              "      <td>compound</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>class</td>\n",
              "      <td>class</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>xxxx</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>NN</td>\n",
              "      <td>in</td>\n",
              "      <td>pobj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>.</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>.</td>\n",
              "      <td>learning</td>\n",
              "      <td>punct</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f8bb793-44fb-4c44-8037-a4bf48682070')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3f8bb793-44fb-4c44-8037-a4bf48682070 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3f8bb793-44fb-4c44-8037-a4bf48682070');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df = pd.DataFrame()\n",
        "df['text'] = [token.text for token in w266_doc]\n",
        "df['lemma'] = [token.lemma_ for token in w266_doc]\n",
        "df['is_punctuation'] = [token.is_punct for token in w266_doc]\n",
        "df['is_space'] = [token.is_space for token in w266_doc]\n",
        "df['shape'] = [token.shape_ for token in w266_doc]\n",
        "df['part_of_speech'] = [token.pos_ for token in w266_doc]\n",
        "df['pos_tag'] = [token.tag_ for token in w266_doc]\n",
        "df['head'] = [token.head.text for token in w266_doc]\n",
        "df['dep'] = [token.dep_ for token in w266_doc]\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awUl7V-bnMIi"
      },
      "source": [
        "\n",
        "\n",
        "[Return to Top](#returnToTop)  \n",
        "<a id = 'spacySVO'></a>\n",
        "\n",
        "### 4.1 SVO Triple Extraction example\n",
        "\n",
        "You can leverage the dependency graph to identify subject-verb-object triples. These can be used to populate a knowledge graph or to extract \"facts\" from text.\n",
        "\n",
        "We need to identify the dependency arc labels that we want to associate with a subject relationship and the labels we want to associate with an object relationship.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKrzZXy_hLnG",
        "outputId": "6b9bbaaa-81a7-4f1f-fdb9-29eca7e21de2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token On POS: ADP, dep: prep\n",
            "Token the POS: DET, dep: det\n",
            "Token afternoon POS: NOUN, dep: pobj\n",
            "Token of POS: ADP, dep: prep\n",
            "Token November POS: PROPN, dep: pobj\n",
            "Token 19 POS: NUM, dep: nummod\n",
            "Token , POS: PUNCT, dep: punct\n",
            "Token 1863 POS: NUM, dep: nummod\n",
            "Token , POS: PUNCT, dep: punct\n",
            "Token Lincoln POS: PROPN, dep: nsubj\n",
            "Token went POS: VERB, dep: ROOT\n",
            "Token to POS: ADP, dep: prep\n",
            "Token Gettysburg POS: PROPN, dep: pobj\n",
            "Token . POS: PUNCT, dep: punct\n",
            "Token He POS: PRON, dep: nsubj\n",
            "Token gave POS: VERB, dep: ROOT\n",
            "Token his POS: PRON, dep: poss\n",
            "Token famous POS: ADJ, dep: amod\n",
            "Token speech POS: NOUN, dep: dobj\n",
            "Token there POS: ADV, dep: advmod\n",
            "Token . POS: PUNCT, dep: punct\n",
            "Token The POS: DET, dep: det\n",
            "Token Gettysburg POS: PROPN, dep: compound\n",
            "Token Address POS: PROPN, dep: nsubj\n",
            "Token began POS: VERB, dep: ROOT\n",
            "Token with POS: ADP, dep: prep\n",
            "Token four POS: NUM, dep: nummod\n",
            "Token score POS: NOUN, dep: pobj\n",
            "Token and POS: CCONJ, dep: cc\n",
            "Token seven POS: NUM, dep: nummod\n",
            "Token years POS: NOUN, dep: npadvmod\n",
            "Token ago POS: ADV, dep: advmod\n",
            "Token . POS: PUNCT, dep: punct\n"
          ]
        }
      ],
      "source": [
        "#SVO extraction\n",
        "\n",
        "# specify object and subject constants\n",
        "OBJECT_DEPS = {\"dobj\", \"dative\", \"attr\", \"oprd\", \"pobj\"}\n",
        "SUBJECT_DEPS = {\"nsubj\", \"nsubjpass\", \"csubj\", \"agent\", \"expl\"}\n",
        "\n",
        "# extract the subject, object and verb from the input\n",
        "def extract_triples(doc):\n",
        "    sub = []\n",
        "    at = []\n",
        "    ve = []\n",
        "    for token in doc:\n",
        "        # is this a verb?\n",
        "        if token.pos_ == \"VERB\":\n",
        "            ve.append(token.text)\n",
        "            #print(\"append to VERB: \"+token.text)\n",
        "        # is this the object?\n",
        "        if token.dep_ in OBJECT_DEPS or token.head.dep_ in OBJECT_DEPS:\n",
        "            at.append(token.text)\n",
        "            #print(\"append to OBJ: \" + token.text)\n",
        "        # is this the subject?\n",
        "        if token.dep_ in SUBJECT_DEPS or token.head.dep_ in SUBJECT_DEPS:\n",
        "            sub.append(token.text)\n",
        "            #print(\"append to SUBJ: \" + token.text)\n",
        "    return \" \".join(sub).strip().lower(), \" \".join(ve).strip().lower(), \" \".join(at).strip().lower()\n",
        "\n",
        "\n",
        "# print out the pos tags and dependency relation labels\n",
        "for token in nnp_doc:\n",
        "    print(\"Token {} POS: {}, dep: {}\".format(token.text, token.pos_, token.dep_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzjIpM7t9bfQ"
      },
      "source": [
        "We'll process our document again, first dividing it into sentences, and then looping through those sentences to extract SVO triples from each sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_F_r-X7IxSdZ",
        "outputId": "98d7ffa4-ebce-407b-944e-768d48c6c736"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First three sentences:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['On the afternoon of November 19, 1863, Lincoln went to Gettysburg.',\n",
              " 'He gave his famous speech there.',\n",
              " 'The Gettysburg Address began with four score and seven years ago.']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#Let's process our nnp_doc again and split it in to sentences.  We'll then operate on each sentence separetely.\n",
        "sentences = list(nnp_doc.sents)\n",
        "sents = []\n",
        "[sents.append(str(sentence)) for sentence in sentences]\n",
        "print(\"First three sentences:\")\n",
        "sents[0:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UAs1ur59xM-"
      },
      "source": [
        "Now, let's iterate through the sentences, extract the SVO triples, and display them in a pandas dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "FatrbqfnxSQW",
        "outputId": "6bc64154-b788-4b37-da0d-476b3a3b7b45"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     subj   verb  \\\n",
              "1                      he   gave   \n",
              "2  the gettysburg address  began   \n",
              "0                 lincoln   went   \n",
              "\n",
              "                                              obj  \n",
              "1                               his famous speech  \n",
              "2                                  four score and  \n",
              "0  the afternoon of november 19 , 1863 gettysburg  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2855b40d-609e-4a01-95bd-d54ad5c2098a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subj</th>\n",
              "      <th>verb</th>\n",
              "      <th>obj</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>he</td>\n",
              "      <td>gave</td>\n",
              "      <td>his famous speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the gettysburg address</td>\n",
              "      <td>began</td>\n",
              "      <td>four score and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>lincoln</td>\n",
              "      <td>went</td>\n",
              "      <td>the afternoon of november 19 , 1863 gettysburg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2855b40d-609e-4a01-95bd-d54ad5c2098a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2855b40d-609e-4a01-95bd-d54ad5c2098a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2855b40d-609e-4a01-95bd-d54ad5c2098a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Create empty lists to store all subject, verbs, and objects\n",
        "subjects = []\n",
        "verbs = []\n",
        "objects = []\n",
        "\n",
        "\n",
        "# Grab the SVOs from each parsed input sentence\n",
        "for sent in sents:\n",
        "    doc = nlp(sent)\n",
        "    s,v,o = extract_triples(doc)\n",
        "    subjects.append(s)\n",
        "    verbs.append(v)\n",
        "    objects.append(o)\n",
        "\n",
        "\n",
        "# store them in a df\n",
        "svo_df = pd.DataFrame({'subj':subjects, 'verb':verbs, 'obj':objects})\n",
        "svo_df.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYfTgvbG78Kb"
      },
      "source": [
        "How well does the system perform on grabbing the subject, verbs, and objects?  Where is it failing? How might we improve the model's performance.\n",
        "\n",
        "We can use these extracted triples to populate a database or to help generate a knowledge graph.\n",
        "\n",
        "That's it for this demo.  Again you are encouraged to experiment with this notebook to build intuition about how systems perform on these tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUwdBJE4xSCr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}